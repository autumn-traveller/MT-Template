%!TEX root = ../thesis.tex

\cleardoublepage
\chapter{Approach}
\label{cha:approach}

To discuss the solution implemented for this thesis requires a review of, firstly, the requirements contained in the problem statement, and, secondly, a description of both the decisions made as well as the process behind making those decisions. To that extent, this chapter will discuss, the components needed in order to address the problem statement. It will try to discuss not only what decisions were made, but also, crucially, what decisions were \textit{not} made, and why. The first section will begin with the fundamental nature of the solution's architecture, thereafter a review of the design requirements which arise from the Deterministic Networking specification will follow, finally the precise nature of the solution's internal workings will be presented.

%%=========================================
\section{Initial Plan}
\label{sec:approach:plan}

At the outset of this thesis it was decided to use a Control User Plane split. The packet processing and forwarding is performed in the user plane, and the control plane makes the high level decisions about which packets to send where, and in this case, on which outgoing interface to send them. The data plane is kept simple and only performs the time critical packet processing, and blindly follows the instructions of the control plane. This type of architecture is very common in modern software-based networks, e.g. OpenFlow, the Evolved Packet Core (from LTE), and the 5G core all implement this kind of split.

%%=========================================
\section{Architectural Components Required for Deterministic Multipath Backhaul in a 5G Campus Environment}
\label{sec:approach:req}


Deterministic networks have been discussed in the previous section. In order to guarantee determinism the IETF DetNet working group has proposed an architecture for determinism over IP networks \cite{detnet-arch}. Their specification identifies four key mechanisms for guaranteeing the determinism of a flow: 1) elimination of contention loss, 2) jitter reduction, 3) service protection, 4) explicit routes. Since the 5G campus environment may need to use the infrastructure of other operators this rules out the usage of explicit routes. A key difference between deterministic networks and 5G campus backhaul is that the operator may not control all the links between nodes, and that there are only two nodes in the network that are definitely under the administrator's control- the core and the edge UPF's and/or WAN connectors. In such a scenario the network is less like a network and more like a client - server application with multiple paths between the client and the server.

\subsection{Elimination of Contention Loss}

Elimination of contention loss can be achieved by using a traffic shaper and/or rate limiter, and the ingress to any DetNet domain \textbf{must} apply such a function. For the WAN Connector therefore a traffic shaper must also be applied to the traffic on ingress, from the RAN, before it is sent across the backhaul links. Since the implementation of a traffic shaper is beyond the scope of this thesis a choice must be made based on the existing solutions. The traffic control subsystem in the linux kernel (TC) provides several implementations of different algorithms for both rate limiting and traffic shaping. Some of these algorithms have already been discussed in the previous section. For the purposes of this solution several algorithms were considered feasible, namely HTB, HFSC, taprio, CAKE, and FQ\_CoDel.

For HTB and HFSC, due to the implementation of these algorithms in the linux tc subsystem, integrating them within the context of this solution would require filters for each flow. This is not necessarily a hindrance yet, however it would introduce additional overhead upon the creation and/or addition of each new flow. Perhaps more importantly, the implementation of the HTB algorithm provides no means for fair queuing. This means that while it is not possible for greedy and/or malicious flows to use up the bandwidth of other flows (because HTB caps bandwidth), the greedy flows can cause other flows to experience higher latency. The HFSC algorithm improves on this by offering both bandwidth and delay guarantees. However this makes it more difficult to configure.

Another feasible option available in linux TC would be the time aware priority queuing (taprio). This queuing discipline provides scheduled gates for specific traffic classes. It could be used to schedule different flows, and/or different priorities, and thus provide a form of prioritization, and, to an extent, traffic shaping. Flows can be assigned different windows (or assigned windows based on their priority) and congestion due to a greedy flow is avoided. However one issue is that taprio fails to provide fair queuing, and thus would need to be configured and possibly adapted as new flows are added and removed, depending on their priority. Greedy flows of the same priority would have to fight each other to use the bandwidth available in their assigned window.

Lastly there are FQ\_CoDel and CAKE. Both provide fair queuing as well as active queue management, which means flows are less likely to experience loss due to congestion, particularly congestion caused by one particularly greedy flow. Since the CAKE algorithm was originally designed for routers in WLAN networks, this may prove to be loosely analogous to a 5G campus network (consider the User Equipment as the Stations, and the Base Station as the Access Point). CAKE also allows the use of priority bins, which fits well with the nature of 5G traffic, where different flows have different priorities. Finally, on a practical level, the implementation of CAKE in the linux kernel uses the kernel's "skb\_flow\_dissector" which exposes a hook point for eBPF \cite{eBPF} programs. Specifically within a 5G context, this could allow one to attach an eBPF program to allow CAKE to peek inside of GTP tunnels, and differentiate the flows within them. For all the other algorithms mentioned so far, all of the GTP packets would appear to belong to the same flow, and thus none of these algorithms would work as expected on the flows being tunneled through GTP. This is ultimately the strongest case that can be made for any of the options listed so far. TC does have one other algorithm which hooks into the "skb\_flow\_dissector", namely the CHOKe qdisc, which does perform queue management, however fails to provide fair queuing.

\subsection{Jitter Reduction and Latency Guarantees}

In the Deterministic Networking Architecture specification it is recommended to adopt time synchronization as well as sending time of execution fields in the application packets, in order to achieve jitter reduction. To this extent the PTP protocol may serve well, especially since there is an existing implementation, the linuxptp project, which extends it to work over IP networks. As for the time of execution fields, it may be possible to place these in a GTP header, or to combine them with timestamping.

Latency guarantees are not mentioned within the specification but they are important for the 5G campus setting. Specifically when backhaul options may include satellite links it becomes important to consider latencies. Additionally, in a multipath setting, latency can be a useful criteria for selecting between links, and guaranteeing latency becomes easier to do when it is possible to switch links should one of them start to experience greater latency than before.

\subsection{Service Protection}

In order to protect against equipment failure, may be recommendable to perform packet duplication and/or encoding. The specification speaks of both duplication of flows, and network coding \cite{network-coding}. This can be a clever solution, however like other parts of the Deterministic Networking specifications, Network Coding requires control over and co-ordination between all the nodes in the network. However to guard against equipment failure and/or packet loss, duplication does provide an option. So too does forward error correction (FEC). Many FEC schemes work on a continuous stream of bytes, providing correction for bit errors, as opposed to correcting the loss of entire packets. There are schemes which address this, fountain codes - such as Raptor \cite{raptor}, but unfortunately their ecosystem is not as developed and because of the complexity involved in implementing them efficiently there are relatively few freely available projects or libraries which can be used to encode packets using such a scheme. For reference, \footnote{https://aff3ct.github.io/fec\_libraries.html} mainaints a list of C\\C++ FEC libraries. Even if it were more feasible to integrate FEC into the backhaul solution it bears questioning how much benefit it brings. FEC is very powerful in situations with consistently lossy links, however internet links tend t experience loss in bursts, as opposed to consistently of the same degree. To this extent it may make more sense to duplicate those flows which require a high degree of reliability. However flow duplication means a packet ordering and elimination function will be required, to eliminate those packets which arrive twice, and to re-order other ones.

TODO!! : detnet POF algorithm

\subsection{Multipath Considerations}

While the previous subsections have all considered requirements for determinism in an IP network, the issue of multipathing still remains. For a component which is backhauling over multiple links in an IP networks this means link and/or path selection is required. Traditionally, routers select links primarily based on their ability to route the packet to the destination, and secondarily based on various metrics, which can be defined by the administrator. For the WAN Connector's scenario routing considerations are not made, its purpose is to backhaul the traffic from the RAN / Edge to the Core, where the network's own internet gateway can perform the routing.

At this point it is crucial to differentiate, again, between multihoming and multipathing. Multihomed hosts are able to select one of many links for their outgoing traffic destined to the same source. In multipathing the same link may lead to multiple paths to \textit{different} destinations. Multipathing over the internet requires complex data collection about all the routers in between the source and the destination, for example \cite{multipath}. 

The goal of this thesis is of course to use the link and/or path selection to provide determinism for the flows being backhauled. To this extent then, the link selection algorithm must attempt to forward flows over paths which can provide at worst the maximum allowed latency and jitter, as well as meeting the minimum reliability. Here it is worth noting that while duplication cannot really be used to guarantee latency, it can be used to improve reliability since a flow which is duplicated across two paths is far less likely to experience packet loss for the same exact packet on both paths.

\subsection{Summary of Requirements}


Looking back on the previous subsections, the following points (in no particular order of priority) were identified as mandatory for a deterministic backhaul solution: 1) traffic shaping, 2) path selection according to jitter and latency requirements, 3) service protection (i.e. via packet duplication), 4) packet ordering and de-duplication, and 5) time synchronization. The ways in which these can be addressed, or quite simply the way in which they were implemented, will be discussed in the following section

%%=========================================
\section{Overview of the WAN Connector's Features and Components}
\label{sec:approach:arch}

\subsection{Path Selection Algorithm}

Meeting the various requirements - jitter, latency, and delay - of a flow can be formulated as a multi-constrained QoS problem. Solving such a multi-constrained QoS problem via path selection is a binary optimization problem. The optimization problem can be posed as such: "select those paths on which to forward packets while making sure to satisfy the latency, jitter and reliability requirements of the given flow, and minimizing the overall weight of the paths used". The mathematical definition is as follows:

\begin{gather}
\text{Minimize } \sum_{i=1}^{P}w(x_i) \\
\text{Where,   } d(i) * x_i\le D \\
j(i) * x_i \le J \\
1 - \prod_{i=1}^{P}{ ( 1- r(i) * x_i ) } \ge R  \\
\text{for } x_i \in \{0,1\}
\end{gather}

Here the variables $D$, $J$, and $R$ are the flow's delay, jitter, and reliability requirements, while the functions $d(i)$, $j(i)$, $r(i)$, $w(i)$ are the estimated delay, jitter, reliability, and weight of link $i$. The predicted values will usually just be the latest measurement, as recommended in \cite{akella2008performance}, however there is room here to use more advanced metrics to predict the future link quality and thus perform preemptive path switching. The total number of paths is $P$. The $x_i$ variable indicates whether or not link $i$ shall be used. If a solution is found, then the flow's packets will be forwarded on each link $i$ where $x_i = 1$, and if no solution can be found which satisfies these conditions then the flow is rejected because its QoS cannot be guaranteed.

It is worth noting that solving such problems is NP-Hard \cite{tsp-np-hard}. However this hardness arises primarily because of line 3.1, the equation for reliability (also the only non-linear equation). Due to this equation one must consider every possible combination of paths on which to forward, and the complexity is $O(2^n)$. This means, even though akella et. al \cite{akella2003measurement} have shown that multihomed approaches experience diminishing returns after more than 4 links, attempting to brute force the solution by limiting the number of paths to 4 still yields a very large problem space - in the worst case both WAN connectors could have 4 outgoing paths, leading to 16 possible paths and thus 65536 possible combinations to consider. In order to further avoid the combinatorial explosion the problem needs to be parameterized even more. The first logical parameterization has already taken place by limiting the number of paths. This can be expanded on by limiting duplication to only take place over disjoint interfaces. No duplication on the same outgoing interface. The reasoning behind this is that in a geographically distributed Campus 5G environment, and especially for environments featuring wireless backhaul (e.g. satellite), it is more likely that a link's reliability is most affected by the over the air transmission on the first hop. By performing this parameterization the problem space shrinks considerably, to just $2^4$ possible combinations of outgoing paths, but because certain paths going out on the same interface are ignored the optimality of the overall solution is gone. This is an acceptable trade off for quick computation, and reasonably strong guarantees on reliability. When choosing from paths to include from a set of paths using the same outgoing link, only the path with the greatest reliability to weight ratio is taken into consideration.

\subsection{Packet Ordering and De-Duplication Function}

Since it is possible for flows to be duplicated across multiple paths, it becomes a necessity to have a packet ordering and elimination function. To be able to re-order and de-duplicate packets means that their sequence numbers need to be tracked. This thesis' implementation will track the sequence number on a per flow basis, using the GTP "sequence number" field. For the packet ordering algorithm the Deterministic Networking Working group provides both a basic and an advanced algorithm in their specification \cite{detnet-pof}. This thesis uses the basic algorithm.

\subsection{Internal Architecture}

\subsubsection{Control - Data Plane Communication}

A protocol is desired which can provide reliable communication over multiple paths in order to communicate between the control plane, where the statistics are collected, flows are added or removed, and the multipath decisions are made, and the data plane. This is crucial, since in a geographically distributed campus 5G deployment it is unlikely that there will be a separate management or control network which uses different underlying network infrastructure than the data plane. Therefore link failure, as well as packet loss, on the link being used by the control plane must either be avoided or protected against. To this extent there are two feasible options - either multipath TCP or SCTP. SCTP supports multihoming and intelligent failover to the multihomed link, and is slightly easier to manage and configure than multipath TCP, which is why it was chosen for the data plane control plane interactions.

\subsubsection{GTP Tunneling and Custom Header Extension}

The tunneling protocol used between the two data plane instances will  be GTP \cite{GTP-spec} version 1. The specification for GTP allows for the use of sequence numbers, as well as the use of extension headers. For the data plane communication there will always be an additional custom header sent which includes a timestamp taken by the sender. The timestamp is taken in microseconds. For the timestamp there are several options available within linux. The atomic clock is used in this implementation because it does not have leap seconds, and so it is a monotonic function, which is an important guarantee for time sensitive applications. Normally, in linux on 64 bit systems, a timestamp takes up 16 bytes and consists of 8 bytes for the time in seconds since the epoch, and another 8 bytes for the nanoseconds. To reduce the footprint of the timestamp in the header, the seconds are represented as an 8 bytes value, thus wrapping around the interval $[0,255]$. The microseconds have a maximum value of $10^6$ and can be represented with just 24 bits. For Wide Area Networks and internet connections usually the latencies are on the order of milliseconds and as such microsecond precision is deemed to be sufficient.

\subsubsection{Metric Collection}

To be able to intelligently switch flows between paths, and to be able to know when this is required, it is necessary to collect the relevant metrics about latency, jitter, bandwidth usage, as well as packet loss. Packet loss can be detected via the sequence numbers, while delay and jitter can be calculated using the timestamps passed along in the GTP headers. These metrics are periodically reported to the control plane so that it can make its decisions on up to date data. Keeping a healthy overview over the state of each path requires periodic probing on these paths. This is especially important for detecting when paths become viable again, since these paths will not have any traffic on them while they are considered down, or if they have experienced high latency and/or jitter recently. The probes are sent once per period of reporting so that they have a minimal impact on the bandwidth usage.

\subsubsection{Flow Descriptions, Flows, and Hashing}

Incoming packets need to be quickly mapped to their respective flows. It is common in network environments to perform flow hashing, in order to quickly lookup which flow incoming packets belong to. This approach makes sense here too. However, since 5G flow descriptions can apply to various IP and port ranges as well as matching based on the transport layer protocol it is not possible to hash an incoming flow and obtain the same hash as the flow description. Furthermore it is possible for a flow to match multiple different flow descriptions. In these cases usually the first matching flow description is taken. This implies some sort of ordered storage of flow descriptions will be required, as well as a method to quickly match packets to flows. The solution used here is to maintain a simple linked list of the known flow descriptions, and match packets to their flow descriptions, if the packet is unknown. For "known" packets, which have been matched to a flow description, these are hashed and stored in a table, alongside their flow descriptor and a list of paths on which the flow is supposed to be forwarded. This allows quick lookup for every subsequent packet, as well as making it simple to change which paths flows are meant to be forwarded on. One alternative to storing the flow descriptions in a linked list would be to store them in a self-balancing binary tree, such as a red-black tree \cite{red-black-trees}, sorted either by priority or ID or even by the hash value of the flow description. This method would provide a faster lookup of new, "unknown" packets, whose hashes don't yet match to a flow, but since new flows are not such a frequent event the overhead may not be worth the gain in performance.

It is important to make a good choice of a hash function. Ideally it should provide less Since the hashes used are only for the purpose of lookups it makes no sense to pick a hashing algorithm designed for us in cryptography. These algorithms are designed so that it is very difficult to reverse engineer the original value from the hash, and this may often make the computation of the hash more computationally intensive than hash algorithms designed for looking up values. Lastly, for hashing algorithms it is desirable that they provide a healthy distribution, to reduce collisions. Collision reduction can also be affected by choice of hash table size, in general it is usually recommended to use prime number. In this implementation, the MurmurHash algorithm was chosen due to its strong performance for lookup-based hashing. Specifically, the MurmurHash3 \cite{murmurhash3} version was chosen, and since it can generate 32 or 128 bit values - the exact sizes of IPv4 and IPv6 addresses - this simplifies the hashing implementation for IP flows. When a packet comes into the WAN connector it is hashed based on it's destination address, source address, destination port, source port, and finally the transport layer protocol number. If the packet was tunneled with a GTP header, the header is removed and the hash is performed on the tunneled packet, not on the GTP packet.

\subsection{Recap and Overview}
TODO: figure


































